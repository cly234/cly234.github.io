<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Chunlin Yu</title>

    <meta name="author" content="Chunlin Yu">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Chunlin Yu
                </p>
                <p>I'm a second-year master's student at <a href="shanghaitech.edu.cn">ShanghaiTech</a> University, where I am currently advised by <a href="https://faculty.sist.shanghaitech.edu.cn/faculty/wangjingya/">Jingya Wang</a>.
                </p>
                <p>
                  Before pursuing the master's degree, I obtained my bachelor's degree from ShanghaiTech University. I've received the Outstanding Student Award in 2023. 
                </p>
                <p style="text-align:center">
                  <a href="yuchl2022@shanghaitech.edu.cn">Email</a> &nbsp;/&nbsp;
                  <a href="data/Resume.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?hl=zh-CN&user=DUOBXBgAAAAJ">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://github.com/cly234">Github</a>
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>
                  My research interests include self-supervised learning and human-centered vision, including but not limited to LLM/LVM, deep clustering, biometric recognition, 2D/3D human-object interaction, and affordances.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/nuvo.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/pdf?id=Psj0jHocm1">
          <span class="papertitle">HybridGait: A Benchmark for Spatial-Temporal Cloth-Changing Gait Recognition with Hybrid Explorations</span>
        </a>
        <br>
	Yilan Dongg*
        <strong>Chunlin Yu*</strong>,
	Ruiyang Ha,
        Ye Shi,
	Yuexin Ma,
	Yanwei Fu,
        Jingya Wang,
        <br>
        <em>AAAI</em>, 2024
        <br>
	<a href="cly234.github.io">Paper</a>
        /
        <a href="cly234.github.io">Code</a>
        <p></p>
        <p>
        A challenging benchmark CCGait that captures realistic appearance changes over expanded time and space, as well as a hybrid framework HybridGait.
        </p>
      </td>
    </tr>
    <tr onmouseout="nuvo_stop()" onmouseover="nuvo_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='nuvo_image'><video  width=100% muted autoplay loop>
          <source src="images/nuvo.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/nuvo.jpg' width=100%>
        </div>
        <script type="text/javascript">
          function nuvo_start() {
            document.getElementById('nuvo_image').style.opacity = "1";
          }

          function nuvo_stop() {
            document.getElementById('nuvo_image').style.opacity = "0";
          }
          nuvo_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://openreview.net/pdf?id=Psj0jHocm1">
          <span class="papertitle">Contextually Affinitive Neighborhood Refinery for Deep Clustering</span>
        </a>
        <br>
        <strong>Chunlin Yu</strong>,
        Ye Shi,
        Jingya Wang,
        <br>
        <em>NeurIPS</em>, 2023
        <br>
	<a href="https://openreview.net/pdf?id=Psj0jHocm1">Paper</a>
        /
        <a href="https://github.com/cly234/DeepClustering-ConNR">Code</a>
        <p></p>
        <p>
        We propose ConAff Neighborhoods for more context-rich neighbor retrievals as well as a progressive Boundary Filtering strategy for noise-resilient neighborhoods.
        </p>
      </td>
    </tr>
	
	
    <tr onmouseout="recon_stop()" onmouseover="recon_start()" bgcolor="#ffffd0">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <div class="one">
          <div class="two" id='recon_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/recon.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/recon.png' width="160">
        </div>
        <script type="text/javascript">
          function recon_start() {
            document.getElementById('recon_image').style.opacity = "1";
          }

          function recon_stop() {
            document.getElementById('recon_image').style.opacity = "0";
          }
          recon_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <a href="https://cly234.github.io/KRKC-projectpage/">
			<span class="papertitle">Lifelong Person Re-Identification via Knowledge Refreshing and Consolidation</span>
        </a>
        <br>
        <strong>Chunlin Yu</strong>,
	Ye Shi,
	Zimo Liu,
	Shenghua Gao,
	Jingya Wang
        <br>
        <em>AAAI</em>, 2023
        <br>
        <a href="https://cly234.github.io/KRKC-projectpage/">project page</a>
        /
        <a href="https://arxiv.org/abs/2211.16201">Paper</a>
        <p></p>
        <p>
        Using a biological-inspired network involving a dynamical memory model and an adaptive working model to refresh and consolidate the knowledge on the fly.
        </p>
      </td>
    </tr>


<tr onmouseout="difsurvey_stop()" onmouseover="difsurvey_start()">
  <td style="padding:20px;width:25%;vertical-align:middle">
    <div class="one">
    <div class="two" id='difsurvey_image'><video  width=100% height=100% muted autoplay loop>
    <source src="images/difsurvey_video.mp4" type="video/mp4">
    Your browser does not support the video tag.
    </video></div>
      <img src='images/difsurvey_image.jpg' width="160">
    </div>
    <script type="text/javascript">
      function difsurvey_start() {
        document.getElementById('difsurvey_image').style.opacity = "1";
      }

      function difsurvey_stop() {
        document.getElementById('difsurvey_image').style.opacity = "0";
      }
      difsurvey_stop()
    </script>
  </td>
  <td style="padding:20px;width:75%;vertical-align:middle">
    <a href="https://arxiv.org/abs/2109.11159">
      <span class="papertitle">Oh-Former: Omni-Relational High-Order Transformer for Person Re-Identification
</span>
    </a>
    <br>
	Xianing Chen, 
	<strong>Chunlin Yu</strong>,
	Qiong Cao, 
	Jialang Xu, 
	Yujie Zhong, 
	Jiale Xu, 
	Zhengxin Li, 
	Jingya Wang, 
	Shenghua Gao
    <br>
	<em>arXiv<em>, 2021
    <br>
    <p></p>
    <p>
    A high-order transformer that captures omni-relational information for person re-identification.
    </p>
  </td>
</tr>         

          </tbody></table>

          
          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
            <tr>
              <td>
                <h2>Services</h2>
              </td>
            </tr>
          </tbody></table>
          <table width="100%" align="center" border="0" cellpadding="20"><tbody>
            
            <tr>
              <td width="75%" valign="center">
                Conference Reviewers:<a href="https://cvpr.thecvf.com/Conferences/2024/Organizers">CVPR 2024</a>, <a href="https://iclr.cc/">ICLR 2024</a>
                <br>
                Journal Reviewers: TNNLS 2022, TMM 2023
                <br>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:right;font-size:small;">
                  Fored from <a href="https://github.com/jonbarron/jonbarron_website">jonbarron's website</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
